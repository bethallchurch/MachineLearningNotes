{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Neural Networks: Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function and Backpropagation\n",
    "\n",
    "We need a cost function for fitting the parameters of a neural network, given a training set.  \n",
    "\n",
    "$\\text{training set } = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})\\}$  \n",
    "\n",
    "Some new terms:  \n",
    "\n",
    "$K$ = the total number of output units  \n",
    "$L$ = the total number of layers in the network  \n",
    "$s_l$ = the total number of units (excluding the bias unit) in layer $l$\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "$y \\in \\{0, 1\\}$  \n",
    "$K = 1$, and so $s_L = 1$  \n",
    "$h_\\Theta(x) \\in \\mathbb{R}$ (i.e. is a real number)\n",
    "\n",
    "### Multiclass Classification\n",
    "\n",
    "$y \\in \\mathbb{R}^K$, i.e. is a vector of dimension $1 \\times K$\n",
    "\n",
    "For example, if each sample could belong to one of three classes (say, an email could be family, friends or work), then:\n",
    "\n",
    "$y \\in \\Bigg\\{ \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\Bigg\\}$\n",
    "\n",
    "$s_L = K$, i.e. number of output units is same as number of classes  \n",
    "$h_\\Theta(x) \\in \\mathbb{R}^K$, i.e. same as y, as usual  \n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Recall that the cost function for regularised logistic regression looks like this:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\bigg[\\sum_{i=1}^{m} y^{(i)}\\log(h_\\theta(x^{(i)})) + (1 - y^{(i)})\\log(1 - h_\\theta(x^{(i)}))\\bigg] + \\frac{\\lambda}{2m}\\sum^n_{j = 1}\\theta^2_j $$\n",
    "\n",
    "The cost function for neural networks is similar, but with a few more nested summations:\n",
    "\n",
    "$$ \\begin{gather*} J(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^K \\left[y^{(i)}_k \\log ((h_\\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\\log (1 - (h_\\Theta(x^{(i)}))_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}} ( \\Theta_{j,i}^{(l)})^2\\end{gather*}$$\n",
    "\n",
    "This is basically a generalisation of the cost function for logistic regression where instead of having one output unit, we have $K$ output units. The regularisation term is just summing over $\\Theta^l_{ji}$ for all values of $j$, $i$ and $l$.\n",
    "\n",
    "### Backpropagation Algorithm\n",
    "\n",
    "The backpropagation algorithm is an algorithm for minimising the cost function in a neural network.  \n",
    "\n",
    "We need to find values of $\\Theta$ that minimises $J(\\Theta)$, i.e. $\\min_\\Theta J(\\Theta)$.\n",
    "\n",
    "Suppose we have just one training sample, $(x, y)$ and a neural network that looks like this (excluding bias units):\n",
    "\n",
    "![Neural Network](https://beths3test.s3.amazonaws.com/machine-learning-notes/nn_3_5_5_4.png)\n",
    "\n",
    "First we perform forward propagation to get the network's prediction:\n",
    "\n",
    "$a^{(1)} = x$  \n",
    "$z^{(2)} = \\Theta^{(1)}a^{(1)}$  \n",
    "$a^{(2)} = g(z^{(2)})$ (don't forget to add the bias unit $a_0^{(2)}$)  \n",
    "$z^{(3)} = \\Theta^{(2)}a^{(2)}$  \n",
    "$a^{(3)} = g(z^{(3)})$  \n",
    "$z^{(4)} = \\Theta^{(3)}a^{(3)}$  \n",
    "$a^{(4)} = h_\\Theta(x) = g(z^{(4)})$  \n",
    "\n",
    "Then we perform backpropagation to adjust the value of $\\Theta$ based on how or right wrong the prediction was.\n",
    "\n",
    "For each node we compute the term $\\delta_j^{l}$, which represents the \"error\" of node $j$ in layer $l$.\n",
    "\n",
    "So for the network above we'd do the following:\n",
    "\n",
    "$\\delta^{(4)} = a^{(4)} - y$ (which is just the difference between the predicted result and the actual result)  \n",
    "$\\delta^{(3)} = (\\Theta^{(3)})^T\\delta^{(4)} \\odot g'(z^{(3)})$  \n",
    "$\\delta^{(2)} = (\\Theta^{(2)})^T\\delta^{(3)} \\odot g'(z^{(2)})$  \n",
    "\n",
    "NB: $\\odot$ here means element-wise multiplication.\n",
    "\n",
    "Notice how the derivative from the subsequent layer is used in calculating the derivative of the layer before it (e.g. $\\delta^{(4)}$ is used in the calculation of $\\delta^{(3)}$. This is how an error is propagated back through the network.\n",
    "\n",
    "Another interesting term is $g'$, which is the derivative of the activation function. In this case the activation function is the sigmoid function, and so $g'(z^{(l)}) = a^{(l)} \\odot (1 - a^{(l)})$.\n",
    "\n",
    "Now suppose we have a training set of $m$ samples, $\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})\\}$.\n",
    "\n",
    "\n",
    "Set $\\Delta^{(l)}_{i,j} := 0$ for all values of $l, i$ and $j$.\n",
    "\n",
    "For training example i = 1:$m$,\n",
    "\n",
    "- Set $a^{(1)} := x^{(i)}$.\n",
    "- Perform forward propagation to compute $a^{(L)}$ for $l = 1, 2, 3, \\dots, L$.\n",
    "- Use the actual result $y^{(t)}$ to compute $\\delta^{(L)} = a^{(L)} - y^{(i)}$.\n",
    "- Compute $\\delta^{(L-1)}, \\delta^{(L-2)},\\dots,\\delta^{(2)}$ using $\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\ \\odot g'(z^{(l)})$ (also written as $\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\ \\odot a^{(l)}\\ \\odot (1 - a^{(l)})$).\n",
    "- $\\Delta^{(l)}_{i,j} := \\Delta^{(l)}_{i,j} + a_j^{(l)} \\delta_i^{(l+1)}$ or, vectorized, $\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T$.\n",
    "\n",
    "Then, outside the for loop, we compute:\n",
    "\n",
    "$D^{(l)}_{i,j} := \\dfrac{1}{m}\\left(\\Delta^{(l)}_{i,j} + \\lambda\\Theta^{(l)}_{i,j}\\right)$  \n",
    "$D^{(l)}_{i,j} := \\dfrac{1}{m}\\Delta^{(l)}_{i,j}$  \n",
    "\n",
    "Once all the values have been computed, $\\frac \\partial {\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = D^{(l)}_{i,j}$, i.e. the partial derivatives of the cost function with respect to its parameters.\n",
    "\n",
    "We can then pass these derivatives to one of the optimisation algorithms.\n",
    "\n",
    "### Backpropagation Intuition\n",
    "\n",
    "Backpropagation actually works in a similar way to forward propagation, but in the opposite direction.\n",
    "\n",
    "The cost function for a neural network is:\n",
    "\n",
    "$$ \\begin{gather*}J(\\Theta) = - \\frac{1}{m} \\sum_{t=1}^m\\sum_{k=1}^K \\left[ y^{(t)}_k \\ \\log (h_\\Theta (x^{(t)}))_k + (1 - y^{(t)}_k)\\ \\log (1 - h_\\Theta(x^{(t)})_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_l+1} ( \\Theta_{j,i}^{(l)})^2\\end{gather*} $$\n",
    "\n",
    "If we ignore regularisation and assume $K = 1$, then the cost for any given training example $(x^{(i)}, y^{(i)})$ is:\n",
    "\n",
    "$$ cost(i) = y^{(i)} \\ \\log (h_\\Theta (x^{(i)})) + (1 - y^{(i)})\\ \\log (1 - h_\\Theta(x^{(i)})) $$\n",
    "\n",
    "This cost plays a similar role to the squared error in linear regression - it measures how wrong the prediction was. So the sum of all of these costs measures how well the network as a whole is doing.\n",
    "\n",
    "Backpropagation is computing $\\delta^{(l)}_j$, which can be thought of as the \"error\" for $a^{(l)}_j$ - it's actually the derivative of $cost(i)$ above:\n",
    "\n",
    "$$ \\delta_j^{(l)} = \\dfrac{\\partial}{\\partial z_j^{(l)}} cost(t) $$\n",
    "\n",
    "That is, the derivative of the cost function for a given node with respect to $z_j^{(l)}$, which is the value passed to the activation function.\n",
    "\n",
    "The derivative is the slope of a line tangent to the cost function, and the steeper it is the further we are from a minimum where the slope is 0, and so the more wrong we are.\n",
    "\n",
    "These derivatives, then, are a measure of how much we'd like to change the neural network's weights in order to affect these intermediate values of the computation, so as to affect the final output of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation in Practice\n",
    "\n",
    "### Unrolling Parameters\n",
    "\n",
    "The advanced optimisation functions like `fminunc` assume a) that the initial theta provided will be in the form of a vector and b) that the gradient return from the cost function will be a vector. To use these functions, then, we need to be able to convert our matrices to a vectors and back again.\n",
    "\n",
    "For example, say we had a neural network such that $s_1 = 10$, $s_2 = 10$ and $s_3 = 1$.\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\Theta^{(1)} \\in \\mathbb{R}^{10 \\times 11}, \\quad \\Theta^{(2)} \\in \\mathbb{R}^{10 \\times 11}, \\quad \\Theta^{(3)} \\in \\mathbb{R}^{1 \\times 11} \\\\\n",
    "D^{(1)} \\in \\mathbb{R}^{10 \\times 11}, \\quad D^{(2)} \\in \\mathbb{R}^{10 \\times 11}, \\quad D^{(3)} \\in \\mathbb{R}^{1 \\times 11}$$  \n",
    "\n",
    "In octave, the following code converts these matrices to vectors:\n",
    "\n",
    "```octave\n",
    "ThetaVec = [Theta1(:); Theta2(:); Theta3(:)];\n",
    "DVec = [D1(:); D2(:); D3(:)];\n",
    "```\n",
    "\n",
    "And this code converts the vectors back to matrices:\n",
    "\n",
    "```octave\n",
    "Theta1 = reshape(ThetaVec(1:110), 10, 11);\n",
    "Theta2 = reshape(ThetaVec(111:220), 10, 11);\n",
    "Theta3 = reshape(ThetaVec(221:231), 1, 11);\n",
    "D1 = reshape(DVec(1:110), 10, 11);\n",
    "D2 = reshape(DVec(111:220), 10, 11);\n",
    "D3 = reshape(DVec(221:231), 1, 11);\n",
    "```\n",
    "\n",
    "So when implementing a neural network:\n",
    "\n",
    "- Unroll to get initial theta for `fminunc`.\n",
    "- In cost function, extract `Theta1`, `Theta2` and `Theta3` from `ThetaVec` parameter.\n",
    "- Use forward / backpropagation to get `D1`, `D2`, `D3` and `J`.\n",
    "- Unroll `D1`, `D2` and `D3` to get `DVec`.\n",
    "\n",
    "### Gradient Checking\n",
    "\n",
    "$$\\dfrac{\\delta}{\\delta\\Theta}J(\\Theta)\\approx \\frac{J(\\Theta + \\epsilon) - J(\\Theta - \\epsilon)}{2\\epsilon}$$\n",
    "\n",
    "Where $\\epsilon$ is some very small value e.g. $10^{-4}$.\n",
    "\n",
    "What this does is approximates the gradient for the current theta values by finding the gradient of the straight line joining the points $\\Theta + \\epsilon$ and $\\Theta - \\epsilon$.\n",
    "\n",
    "With multiple $\\Theta$ matrices, the formula is:\n",
    "\n",
    "$$ \\dfrac{\\delta}{\\delta\\Theta_j}J(\\Theta)\\approx \\frac{J(\\Theta_1, \\dots, \\Theta_j + \\epsilon, \\dots, \\Theta_n) - J(\\Theta_1, \\dots, \\Theta_j - \\epsilon, \\dots, \\Theta_n)}{2\\epsilon} $$\n",
    "\n",
    "An octave implementation of this might look like:\n",
    "\n",
    "```octave\n",
    "epsilon = 1e-4;\n",
    "for i = 1:n,\n",
    "  thetaPlus = theta;\n",
    "  thetaPlus(i) += epsilon;\n",
    "  thetaMinus = theta;\n",
    "  thetaMinus(i) -= epsilon;\n",
    "  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)\n",
    "end;\n",
    "```\n",
    "\n",
    "We can use this to check that the values for the derivative are accurate - but turn it off before training the network for real because it's very computationally expensive.\n",
    "\n",
    "### Random Initialisation\n",
    "\n",
    "We need some initial value for $\\Theta$. Previously we've set it to a vector of all 0s, but this won't work for neural networks.\n",
    "\n",
    "If you set $\\Theta_{ij}^{(l)} = 0$ for all $i, j, l$ then all the nodes in the network will update to the same value and all the derivatives will update to the same value. After each update, parameters corresponding to inputs going into each of the hidden units are identical.\n",
    "\n",
    "This is known as the problem of symmetric weights. We can fix it by doing some symmetry breaking. This can be achieved by setting each $\\Theta_{ij}^{(l)}$ to some random value in $[-\\epsilon \\epsilon]$. (Nothing to do with the $\\epsilon$ in the section above.)\n",
    "\n",
    "In octave:\n",
    "\n",
    "```octave\n",
    "% If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.\n",
    "Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;\n",
    "Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;\n",
    "Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;\n",
    "```\n",
    "\n",
    "### Putting It Together\n",
    "\n",
    "Pick a neural network architecture:\n",
    "\n",
    "- Number of input units = number of features $x^{(i)}$.\n",
    "- Number of output units = number of classes.\n",
    "- Number of hidden units = more is generally better (although more computationally expensive); have at least as many as input units.\n",
    "- Default to one hidden layer.\n",
    "\n",
    "More on designing an architecture in coming weeks!\n",
    "\n",
    "Training a neural network:\n",
    "\n",
    "- Randomly initialise the theta values / weights.\n",
    "- Forward propagation to get predictions.\n",
    "- Implement the cost function.\n",
    "- Backpropagation to get the partial derivatives.\n",
    "- Check backpropagation working properly with gradient checking -> then turn off gradient checking.\n",
    "- Pass cost function and derivatives to some advanced optimisation function e.g. `fminunc` to minimise the cost function with the weights in theta.\n",
    "\n",
    "N.B. $J(\\Theta)$ is not convex, so you might end up in a local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
