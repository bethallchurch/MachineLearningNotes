{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advice for Applying Machine Learning\n",
    "\n",
    "What should you do if your (e.g.) regularised linear regression model is making unacceptably large errors in its predictions?\n",
    "\n",
    "Options include:\n",
    "\n",
    "+ Collect more training examples.\n",
    "+ Try smaller sets of features.\n",
    "+ Try getting additional features.\n",
    "+ Try adding polynomial features.\n",
    "+ Try decreasing $\\lambda$.\n",
    "+ Try increasing $\\lambda$.\n",
    "\n",
    "How do you know which to try first?\n",
    "\n",
    "Machine learning diagnostic:  \n",
    "A diagnostic is a test that you can run to gain insight into what is or isn't working with a learning algorithm, and gain guidance as to how best to improve its performance.\n",
    "\n",
    "Diagnostics can take time to implement, but are worth it in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Hypothesis\n",
    "\n",
    "A really low value of training error might indicate overfitting rather than accuracy. For this reason you should always divide your (randomly ordered) data into a training set and a test set - a 70:30 split is typical - and check the error on the test set after the model has been trained with the training set data. A low value for training error and a high value for test error suggests overfitting.\n",
    "\n",
    "Procedure:  \n",
    "\n",
    "+ Learn parameter $\\theta$ from training data (minimising training error $J(\\theta)$).\n",
    "+ Compute test error (for e.g. linear regression): $$J_{test}(\\theta) = \\frac{1}{2m} \\sum^{m_{test}}_{i = 1} (h_\\theta(x^{(i)}_{test}) - y^{(i)}_{test})^2$$\n",
    "+ Compare test error with training error.\n",
    "\n",
    "For logistic regression, you can use test error as follows:\n",
    "\n",
    "$$J_{test}(\\theta) = -\\frac{1}{m_{test}} \\sum^{m_{test}}_{i = 1} y^{(i)}_{test} \\log h_\\theta(x^{(i)}_{test}) + (1 - y^{(i)}_{test})\\log h_\\theta(x^{(i)}_{test}) $$\n",
    "\n",
    "Or an alternative error metric, the misclassification error:\n",
    "\n",
    "$$ err(h_\\theta(x), y) =\n",
    "\\begin{cases}\n",
    " 1 \\text{ if } h_{x} \\geq 0.5, y = 1 \\text{ or } h_{x} < 0.5, y = 0 \\\\\n",
    " 0 \\text{ otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "That is, 1 if the sample was misclassified, 0 otherwise. Then average these values to give you an idea of how many samples your hypothesis is misclassifying:\n",
    "\n",
    "$$ \\text{test error } = \\frac{1}{m_{test}} \\sum^{m_{test}}_{i = 1} err(h_\\theta(x^{(i)}_{test}), y^{(i)}_{test}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
