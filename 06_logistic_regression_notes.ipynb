{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Logistic Regression\n",
    "\n",
    "* [Classification and Representation](#Classification-and-Representation)\n",
    "    - [Classification](#Classification)\n",
    "    - [Hypothesis Representation](#Hypothesis-Representation)\n",
    "    - [Decision Boundary](#Decision-Boundary)\n",
    "* [Logistic Regression Model](#Logistic-Regression-Model)\n",
    "    - [Cost Function](#Cost-Function)\n",
    "    - [Simplified Cost Function and Gradient Descent](#Simplified-Cost-Function-and-Gradient-Descent)\n",
    "    - [Advanced Optimization](#Advanced-Optimization)\n",
    "* [Multiclass Classification](#Multiclass-Classification)\n",
    "    - [One-vs-all](#One-vs-all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Despite the appearance of the term 'regression', logistic regression is actually a classification algorithm. First we'll consider binary classification, where the output y is such that:\n",
    "\n",
    "$$ y \\in \\{0, 1\\} $$\n",
    "\n",
    "That is, y is either 1 or 0; it belongs to the positive class or the negative class. For example, we might use logistic regression to predict whether an email is spam or not spam.\n",
    "\n",
    "Unlike in linear regression where $ h_\\theta(x) $ can be greater than 1 or less that zero, in logistic regression $ h_\\theta(x) $ always predicts a value between 1 and 0.\n",
    "\n",
    "$$ 0 \\leq h_\\theta(x) \\leq 1 $$\n",
    "\n",
    "Given $x(i)$, the corresponding $y(i)$ is also called the label for the training example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Representation\n",
    "\n",
    "We want the output of our hypothesis to be such that $ 0 \\leq h_\\theta(x) \\leq 1 $.  In linear regression, our hypothesis was:\n",
    "\n",
    "$$ h_\\theta(x) = \\theta^Tx $$\n",
    "\n",
    "For logistic regression, our hypothesis will be:\n",
    "\n",
    "$$ h_\\theta(x) = g(\\theta^Tx) $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "The function $g(z)$ is called the sigmoid or logistic function. We're using the sigmoid function because it maps any real number to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification. Graphically:\n",
    "\n",
    "![Sigmoid Functoin](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/1WFqZHntEead-BJkoDOYOw_2413fbec8ff9fa1f19aaf78265b8a33b_Logistic_function.png?expiry=1489795200000&hmac=Y4G3nyImatzjeqX9-3GXqFAu-NGhMnfBLN8QQ4k65V4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite our hypothesis function as:\n",
    "\n",
    "$$ h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}} $$\n",
    "\n",
    "We can treat the output of $h_\\theta(x)$ as the probability that $y = 1$ on input $x$. That is:\n",
    "\n",
    "$$ h_\\theta(x) = P(y = 1 | x; \\theta) $$  \n",
    "\n",
    "<center>*\"The probability that $y$ equals 1, given $x$, parameterised by $\\theta$.\"*</center>\n",
    "\n",
    "Remember that:\n",
    "\n",
    "$$ 1 = P(y = 1 | x; \\theta) + P(y = 0 | x; \\theta) $$  \n",
    "\n",
    "i.e. The probability that $y$ is equal to 1 or 0 is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary\n",
    "\n",
    "Suppose we predict $y = 1$ if $ h_\\theta(x) \\geq 0.5 $ and $y = 0$ if $ h_\\theta(x) < 0.5 $. When will it be the case that $ h_\\theta(x) \\geq 0.5 $? If we look at the graph of the sigmoid function above we can see that:\n",
    "\n",
    "$$\n",
    "\\begin{align*}z=0, e^{0}=1 \\Rightarrow g(z)=0.5\\newline z \\to \\infty, e^{-\\infty} \\to 0 \\Rightarrow g(z)=1 \\newline z \\to -\\infty, e^{\\infty}\\to \\infty \\Rightarrow g(z)=0 \\end{align*}\n",
    "$$\n",
    "\n",
    "Since on our hypothesis, $z = \\theta^Tx$:\n",
    "\n",
    "$$ h_\\theta(x) = g(\\theta^Tx) \\geq 0.5 $$\n",
    "\n",
    "$$ whenever $$\n",
    "\n",
    "$$ \\theta^Tx \\geq 0 $$\n",
    "\n",
    "Say we have two input features, $x_1$ and $x_2$, so that:\n",
    "\n",
    "$$ h_\\theta(x) = g(\\theta_0 + \\theta_1x_1 + \\theta_2x_2) $$\n",
    "\n",
    "And say that our learning algorithm (which is TBD) has decided on the values $\\theta_0 = 3$, $\\theta_1 = 1$ and $\\theta_2 = 1$.\n",
    "\n",
    "Then we can say:\n",
    "\n",
    "$$\\text{Predict } y = 1 \\text{ if } -3 + x_1 + x_2 \\geq 0 $$\n",
    "\n",
    "The line $x_1 + x_2 = 3$ on the graph of $x_1$ vs $x_2$ marks the *decision boundary*. On this line, $h_\\theta(x) = 0.5$ exactly. Any sample that falls in the region to the top right of this line where $x_1 + x_2 > 3$ has a predicted output value of 1. Any sample that falls in the region to the bottom left of this line where $x_1 + x_2 < 3$ has a predicted output value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : graph 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the sigmoid function $g(z)$ (e.g. $\\theta^Tx$) doesn't need to be linear, and could be a function that describes a circle (e.g. $z = \\theta_0 + \\theta_1x_1^2+\\theta_2x_2^2$) or any shape to fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : graph 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "We have a training set:\n",
    "\n",
    "$$ {(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\dots, (x^{(m)}, y^{(m)})} $$\n",
    "\n",
    "With $m$ samples. Each $x$ is a feature vector like so:\n",
    "\n",
    "$$ x \\in \\begin{bmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "\\vdots \\\\\n",
    "x_n \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where $x_0 = 1$. The output values for $y$ can be 0 or 1, so: \n",
    "\n",
    "$$y \\in \\{0, 1\\}$$\n",
    "\n",
    "Our hypothesis looks like this:\n",
    "\n",
    "$$ h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}} $$\n",
    "\n",
    "And $\\theta$ is a vector like:\n",
    "\n",
    "$$ \\theta \\in \\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "How do we choose values for the parameters $\\theta$?\n",
    "\n",
    "Our cost function for linear regression looks like this:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\displaystyle \\sum_{i=1}^{m} \\frac{1}{2}(h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "We can't really use this cost function for logistic regression, because, when combined with our hypothesis, its graph is non-convex. It has lots of local minima and so gradient descent can't be guaranteed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : graph 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract part of the cost function for linear regression above:\n",
    "\n",
    "$$ \\text{Cost}(h_\\theta(x), y) = \\frac{1}{2}(h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\displaystyle \\sum_{i=1}^{m} \\text{Cost}(h_\\theta(x), y) $$\n",
    "\n",
    "We want to keep the idea of summing over the training set, but modify the specifics of how we calculate the cost itself. For logistic regression, the crucial part of the cost function will be:\n",
    "\n",
    "$$ \\text{Cost}(h_\\theta(x), y) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "      -\\log(h_\\theta(x)) \\text{ if } y = 1\\\\\n",
    "      -\\log(1 - h_\\theta(x)) \\text{ if } y = 0\n",
    "    \\end{array}\n",
    "  \\right. $$\n",
    "  \n",
    "To see why this works, first consider the case where $y = 1$ and so the cost is $-\\log(h_\\theta(x))$. The graph of $-\\log(h_\\theta(x))$ looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : graph 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the graph that when $y = 1$ and $h_\\theta(x) = 1$ the cost is 0, yet as $h_\\theta(x) \\to 0$, cost $\\to \\infty$. That is, the less confident our hypothesis is that the correct value is 1 (which it is), the greater the cost.\n",
    "\n",
    "Now let's consider the case where *y = 0* and the cost is $-\\log(1 - h_\\theta(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO : graph 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, when $y = 0$ and $h_\\theta(x) = 0$ the cost is 0, and as $h_\\theta(x) \\to 1$, cost $\\to \\infty$. The less confident the hypothesis is that $y = 0$, the higher the cost.\n",
    "\n",
    "Notice as well that for both graphs the cost function is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Cost Function and Gradient Descent\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "Our overall cost function is:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\text{Cost}(h_\\theta(x), y) $$\n",
    "  \n",
    "Where:\n",
    "\n",
    "$$ \\text{Cost}(h_\\theta(x), y) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "  -\\log(h_\\theta(x)) \\text{ if } y = 1\\\\\n",
    "  -\\log(1 - h_\\theta(x)) \\text{ if } y = 0\n",
    "\\end{array}\n",
    "\\right. $$\n",
    "\n",
    "We can condense this onto one line:\n",
    "\n",
    "$$\\text{Cost}(h_\\theta(x), y) = -y\\log(h_\\theta(x)) - (1 - y)\\log(1 - h_\\theta(x))$$\n",
    "\n",
    "To see why this is equivalent, remember that *y* can only be 1 or 0. Try substituting in *y = 0*. The first part of the right hand side is cancelled out and you're left with $-\\log(1 - h_\\theta(x))$. Then try substituting in *y = 1*. The second part of the right hand side disappears leaving $-\\log(h_\\theta(x))$.\n",
    "\n",
    "In full, then, our cost function for logistic regression is:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\bigg[\\sum_{i=1}^{m} y^{(i)}\\log(h_\\theta(x^{(i)})) + (1 - y^{(i)})\\log(1 - h_\\theta(x^{(i)}))\\bigg] $$\n",
    "\n",
    "Vectorised:\n",
    "\n",
    "$$ h = g(X\\theta) $$\n",
    "$$ J(\\theta) = \\frac{1}{m} \\cdot (-y^T\\log(h) - (1 - y)^T\\log(1 - h) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "Since $J(\\theta)$ is convex, we can use the gradient descent algorithm:\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\text{Repeat } \\{ \\\\\n",
    "&\\qquad\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta) \\\\\n",
    "&\\}\n",
    "\\end{align*}$$\n",
    "\n",
    "Finding the partial derivate of the cost function gives us:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{m}\\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "Our gradient descent algorithm now looks like this:\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\text{Repeat } \\{ \\\\\n",
    "&\\qquad\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i = 1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\\\\n",
    "&\\}\n",
    "\\end{align*}$$\n",
    "\n",
    "Which looks exactly the same as our gradient descent algorithm for linear regression! However, it's not the same as the hypothesis is different.\n",
    "\n",
    "A vectorised implementation of the gradient descent algorithm:\n",
    "\n",
    "$$\\theta := \\theta - \\alpha\\frac{1}{m}\\sum_{i = 1}^m [(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}]$$\n",
    "\n",
    "or more compactly:\n",
    "\n",
    "$$\\theta := \\theta - \\frac{\\alpha}{m}X^T(g(X\\theta) - \\overrightarrow{y})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Optimization\n",
    "\n",
    "Gradient descent isn't the only optimization algorithm on the market. You could also use one of the following:\n",
    "\n",
    "- Conjugate gradient\n",
    "- BFGS\n",
    "- L-BFGS\n",
    "\n",
    "These are often faster than gradient descent, plus they don't require you to choose a value for alpha. On the downside, they're more complex so you shouldn't try to implement them yourself. However there are plenty of implementations available in various languages so you can use one of those.\n",
    "\n",
    "To use one of these advanced optimization algorithms in Octave, first you have to provide a function that evaluates the following two functions for a given input value $\\theta$: \n",
    "\n",
    "$$ J(\\theta) $$\n",
    "$$ \\frac{\\partial}{\\partial\\theta_j}J(\\theta) $$\n",
    "\n",
    "Which might look like this:\n",
    "\n",
    "```octave\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "  jVal = [...code to compute J(theta)...];\n",
    "  gradient = [...code to compute derivative of J(theta)...];\n",
    "end\n",
    "```\n",
    "\n",
    "Then we can use octave's \"fminunc()\" optimization algorithm along with the \"optimset()\" function that creates an object containing the options we want to send to \"fminunc()\".\n",
    "\n",
    "```octave\n",
    "options = optimset('GradObj', 'on', 'MaxIter', 100);\n",
    "initialTheta = zeros(2,1);\n",
    "   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);\n",
    "```\n",
    "\n",
    "We give to the function \"fminunc()\" our cost function, our initial vector of theta values, and the \"options\" object that we created beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-all\n",
    "\n",
    "Say you have a number of discrete categories that you want to sort your data into. For example, for you might want to train a classifier that can predict whether an email should be put into as work, friends or family folders.\n",
    "\n",
    "$y$ can now take on a range of values, in this example 1, 2 or 3.\n",
    "\n",
    "Train a logistic regression classifier $h_\\theta(x)$ for each class￼ to predict the probability that $y = i￼$, i.e. go through each class in turn treating it as the positive class and all the others as negative until you have values for the $\\theta$ parameters for each one.\n",
    "\n",
    "$$h_\\theta^{(i)}(x) = P(y = i|x;\\theta) (i = 1, 2, 3)$$\n",
    "\n",
    "To make a prediction on a new $x$, pick the class ￼that maximizes $h_\\theta(x)$, i.e. pick the most confident."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
